{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's first use this notebook to write the necessary functions, and then later save it as .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "    return e_x/ e_x.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN_numpy/Images/rnn_step_forward.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 2**: Basic RNN cell. Takes as input $x^{\\langle t \\rangle}$ (current input) and $a^{\\langle t-1\\rangle}$ (previous hidden state containing information from the past), and outputs $a^{\\langle t \\rangle}$ which is given to the next RNN cell and also used to predict $y^{\\langle t \\rangle}$</caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first write a function for initializing parameters for the model. we need n_x, n_a & n_y for initilaizing the weight and bias matrices to right dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_a, n_y):\n",
    "    \"\"\"\n",
    "    Initialize paarmeters with small random values\n",
    "    \n",
    "    Input: n_x (dimension of input x), n_a (dimension of units in hidden state)\n",
    "            n_y (dimension of output y)\n",
    "            \n",
    "    returns parameters -- python dictionary containing :\n",
    "    Wax - (n_a,n_X) Weight matrix multiplying the input\n",
    "    Waa - (n_a,n_a) Weight matrix multiplying the hidden state\n",
    "    Wya - (n_y,n_a) Weight matrix for hidden state to output\n",
    "    b - (n_a, 1) Bias\n",
    "    by - (n_y, 1) Bias for hidden state of output\n",
    "    \"\"\"\n",
    "    np.random.seed(1) #can change the seed or remove this line\n",
    "    \n",
    "    Wax = np.random.randn(n_a, n_x)*0.01 #input to hidden\n",
    "    Waa = np.random.randn(n_a, n_a)*0.01 #hidden to hidden\n",
    "    Wya = np.random.randn(n_y, n_a)*0.01 #hidden to output\n",
    "    b = np.zeros((n_a,1)) #hidden bias\n",
    "    by = np.zeros((n_y,1)) #output bias\n",
    "    \n",
    "    parameters = {\"Wax\":Wax, \"Waa\":Waa, \"Wya\":Wya, \"b\":b, \"by\":by}\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "\n",
    "#paratest = initialize_parameters(3,4,5)\n",
    "#paratest['Wax'].shape, paratest['Waa'].shape, paratest['Wya'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for executing one forward step of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_step_forward(parameters, a_prev, x):\n",
    "    \"\"\"\n",
    "    Function to implement a single forward prop step in a single RNN cell\n",
    "    \n",
    "    Input :\n",
    "    parametrs : dictionary with Wax, Waa, Wya, b, by\n",
    "    a_prev : Hidden state at previous time step \n",
    "    x : Input at time t\n",
    "    \n",
    "    Returns:\n",
    "    a_next : hidden state for this RNN cell\n",
    "    p_t : probabilities for next chars\n",
    "    \"\"\"\n",
    "    Wax, Waa, Wya, b, by = parameters[\"Wax\"], parameters[\"Waa\"], parameters[\"Wya\"], parameters[\"b\"], parameters[\"by\"]\n",
    "    \n",
    "    a_next = np.tanh(np.dot(Wax,x)+np.dot(Waa,a_prev)+b)\n",
    "    p_t = softmax(np.dot(Wya,a_next)+by)\n",
    "    \n",
    "    return a_next, p_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check\n",
    "#rtest, ytest = rnn_step_forward(paratest, np.random.randn(4,1), np.random.randn(3,1))\n",
    "#rtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for backward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_step_backward(dy, gradients, parameters, x, a, a_prev):\n",
    "    gradients['dWya'] += np.dot(dy, a.T)\n",
    "    gradients['dby'] += dy\n",
    "    da = np.dot(parameters['Wya'].T, dy) + gradients['da_next']\n",
    "    daraw = (1-a*a)*da\n",
    "    gradients['db'] += daraw\n",
    "    gradients['dWax'] += np.dot(daraw, x.T)\n",
    "    gradients['dWaa'] += np.dot(daraw, a_prev.T)\n",
    "    gradients['da_next'] = np.dot(parameters['Waa'].T, daraw)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, lr):\n",
    "    parameters['Wax'] += -lr*gradients['dWax']\n",
    "    parameters['Waa'] += -lr*gradients['dWaa']\n",
    "    parameters['Wya'] += -lr * gradients['dWya']\n",
    "    parameters['b'] += -lr * gradients['db']\n",
    "    parameters['by'] += -lr * gradients['dby']\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run RNN Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_forward(X, Y, a0, parameters, vocab_size):\n",
    "    x,a,y_hat = {}, {}, {}\n",
    "    a[-1] = np.copy(a0)\n",
    "    loss = 0\n",
    "    \n",
    "    for t in range(len(X)):\n",
    "        x[t] = np.zeros((vocab_size,1))\n",
    "        if (X[t] != None):\n",
    "            x[t][X[t]] = 1\n",
    "            \n",
    "        a[t], y_hat[t] = rnn_step_forward(parameters, a[t-1], x[t])\n",
    "        \n",
    "        loss -= np.log(y_hat[t][Y(t),0])\n",
    "        \n",
    "    cache = (y_hat, a, x)\n",
    "    \n",
    "    return loss, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_backward(X, Y, parameters, cache):\n",
    "    gradients = {}\n",
    "    (y_hat, a, x) = cache\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    gradients['dWax'], gradients['dWaa'], gradients['dWya'] = np.zeros_like(Wax), np.zeros_like(Waa), np.zeros_like(Wya)\n",
    "    gradients['db'], gradients['dby'] = np.zeros_like(b), np.zeros_like(by)\n",
    "    gradients['da_next'] = np.zeros_like(a[0])\n",
    "    \n",
    "    for t in reversed(range(len(X))):\n",
    "        dy = np.copy(y_hat[t])\n",
    "        dy[Y[t]] -= 1\n",
    "        gradients = rnn_step_backward(dy, gradients, parameters, x[t],a[t],a[t-1])\n",
    "        \n",
    "    return gradients, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
